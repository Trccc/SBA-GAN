{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = np.load('testcase.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4341],\n",
       "        [4217],\n",
       "        [ 907],\n",
       "        [3066],\n",
       "        [3068],\n",
       "        [4472],\n",
       "        [  81],\n",
       "        [3066],\n",
       "        [1394],\n",
       "        [3484],\n",
       "        [1946],\n",
       "        [1394],\n",
       "        [3267],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import range\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from miscc.config import cfg\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import build_super_images, build_super_images2\n",
    "from miscc.utils import weights_init, load_params, copy_G_params\n",
    "from model import G_DCGAN, G_NET\n",
    "from datasets import prepare_data\n",
    "from model import RNN_ENCODER, CNN_ENCODER\n",
    "\n",
    "from miscc.losses import words_loss\n",
    "from miscc.losses import discriminator_loss, generator_loss, KL_loss\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# ################# Text to image task############################ #\n",
    "class condGANTrainer(object):\n",
    "    def __init__(self, output_dir, data_loader, n_words, ixtoword):\n",
    "        if cfg.TRAIN.FLAG:\n",
    "            self.model_dir = os.path.join(output_dir, 'Model')\n",
    "            self.image_dir = os.path.join(output_dir, 'Image')\n",
    "            mkdir_p(self.model_dir)\n",
    "            mkdir_p(self.image_dir)\n",
    "\n",
    "        torch.cuda.set_device(cfg.GPU_ID)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        self.batch_size = cfg.TRAIN.BATCH_SIZE\n",
    "        self.max_epoch = cfg.TRAIN.MAX_EPOCH\n",
    "        self.snapshot_interval = cfg.TRAIN.SNAPSHOT_INTERVAL\n",
    "\n",
    "        self.n_words = n_words\n",
    "        self.ixtoword = ixtoword\n",
    "        self.data_loader = data_loader\n",
    "        self.num_batches = len(self.data_loader)\n",
    "\n",
    "    def build_models(self):\n",
    "        # ###################encoders######################################## #\n",
    "        ## text for input sentece and image for final image.\n",
    "        if cfg.TRAIN.NET_E == '':\n",
    "            print('Error: no pretrained text-image encoders')\n",
    "            return\n",
    "\n",
    "        image_encoder = CNN_ENCODER(cfg.TEXT.EMBEDDING_DIM)\n",
    "        img_encoder_path = cfg.TRAIN.NET_E.replace('text_encoder', 'image_encoder')\n",
    "        state_dict = \\\n",
    "            torch.load(img_encoder_path, map_location=lambda storage, loc: storage)\n",
    "        image_encoder.load_state_dict(state_dict)\n",
    "        for p in image_encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        print('Load image encoder from:', img_encoder_path)\n",
    "        image_encoder.eval()\n",
    "        \n",
    "        text_encoder = \\\n",
    "            RNN_ENCODER(self.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
    "        state_dict = \\\n",
    "            torch.load(cfg.TRAIN.NET_E,\n",
    "                       map_location=lambda storage, loc: storage)\n",
    "        text_encoder.load_state_dict(state_dict)\n",
    "        for p in text_encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        print('Load text encoder from:', cfg.TRAIN.NET_E)\n",
    "        text_encoder.eval()\n",
    "\n",
    "        # #######################generator and discriminators############## #\n",
    "        netsD = []\n",
    "        if cfg.GAN.B_DCGAN:\n",
    "            if cfg.TREE.BRANCH_NUM ==1:\n",
    "                from model import D_NET64 as D_NET\n",
    "            elif cfg.TREE.BRANCH_NUM == 2:\n",
    "                from model import D_NET128 as D_NET\n",
    "            else:  # cfg.TREE.BRANCH_NUM == 3:\n",
    "                from model import D_NET256 as D_NET\n",
    "            # TODO: elif cfg.TREE.BRANCH_NUM > 3:\n",
    "            netG = G_DCGAN()\n",
    "            netsD = [D_NET(b_jcu=False)]\n",
    "        else:\n",
    "            from model import D_NET64, D_NET128, D_NET256\n",
    "            netG = G_NET()\n",
    "            if cfg.TREE.BRANCH_NUM > 0:\n",
    "                netsD.append(D_NET64())\n",
    "            if cfg.TREE.BRANCH_NUM > 1:\n",
    "                netsD.append(D_NET128())\n",
    "            if cfg.TREE.BRANCH_NUM > 2:\n",
    "                netsD.append(D_NET256())\n",
    "            # TODO: if cfg.TREE.BRANCH_NUM > 3:\n",
    "        netG.apply(weights_init)\n",
    "        # print(netG)\n",
    "        for i in range(len(netsD)):\n",
    "            netsD[i].apply(weights_init)\n",
    "            # print(netsD[i])\n",
    "        print('# of netsD', len(netsD))\n",
    "        #\n",
    "        epoch = 0\n",
    "        if cfg.TRAIN.NET_G != '':\n",
    "            state_dict = \\\n",
    "                torch.load(cfg.TRAIN.NET_G, map_location=lambda storage, loc: storage)\n",
    "            netG.load_state_dict(state_dict)\n",
    "            print('Load G from: ', cfg.TRAIN.NET_G)\n",
    "            istart = cfg.TRAIN.NET_G.rfind('_') + 1\n",
    "            iend = cfg.TRAIN.NET_G.rfind('.')\n",
    "            epoch = cfg.TRAIN.NET_G[istart:iend]\n",
    "            epoch = int(epoch) + 1\n",
    "            if cfg.TRAIN.B_NET_D:\n",
    "                Gname = cfg.TRAIN.NET_G\n",
    "                for i in range(len(netsD)):\n",
    "                    s_tmp = Gname[:Gname.rfind('/')]\n",
    "                    Dname = '%s/netD%d.pth' % (s_tmp, i)\n",
    "                    print('Load D from: ', Dname)\n",
    "                    state_dict = \\\n",
    "                        torch.load(Dname, map_location=lambda storage, loc: storage)\n",
    "                    netsD[i].load_state_dict(state_dict)\n",
    "        # ########################################################### #\n",
    "        if cfg.CUDA:\n",
    "            text_encoder = text_encoder.cuda()\n",
    "            image_encoder = image_encoder.cuda()\n",
    "            netG.cuda()\n",
    "            for i in range(len(netsD)):\n",
    "                netsD[i].cuda()\n",
    "        return [text_encoder, image_encoder, netG, netsD, epoch]\n",
    "\n",
    "    def define_optimizers(self, netG, netsD):\n",
    "        optimizersD = []\n",
    "        num_Ds = len(netsD)\n",
    "        for i in range(num_Ds):\n",
    "            opt = optim.Adam(netsD[i].parameters(),\n",
    "                             lr=cfg.TRAIN.DISCRIMINATOR_LR,\n",
    "                             betas=(0.5, 0.999))\n",
    "            optimizersD.append(opt)\n",
    "\n",
    "        optimizerG = optim.Adam(netG.parameters(),\n",
    "                                lr=cfg.TRAIN.GENERATOR_LR,\n",
    "                                betas=(0.5, 0.999))\n",
    "\n",
    "        return optimizerG, optimizersD\n",
    "\n",
    "    def prepare_labels(self):\n",
    "        batch_size = self.batch_size\n",
    "        real_labels = Variable(torch.FloatTensor(batch_size).fill_(1))\n",
    "        fake_labels = Variable(torch.FloatTensor(batch_size).fill_(0))\n",
    "        match_labels = Variable(torch.LongTensor(range(batch_size)))\n",
    "        if cfg.CUDA:\n",
    "            real_labels = real_labels.cuda()\n",
    "            fake_labels = fake_labels.cuda()\n",
    "            match_labels = match_labels.cuda()\n",
    "\n",
    "        return real_labels, fake_labels, match_labels\n",
    "\n",
    "    def save_model(self, netG, avg_param_G, netsD, epoch):\n",
    "        backup_para = copy_G_params(netG)\n",
    "        load_params(netG, avg_param_G)\n",
    "        torch.save(netG.state_dict(),\n",
    "            '%s/netG_epoch_%d.pth' % (self.model_dir, epoch))\n",
    "        load_params(netG, backup_para)\n",
    "        #\n",
    "        for i in range(len(netsD)):\n",
    "            netD = netsD[i]\n",
    "            torch.save(netD.state_dict(),\n",
    "                '%s/netD%d.pth' % (self.model_dir, i))\n",
    "        print('Save G/Ds models.')\n",
    "\n",
    "    def set_requires_grad_value(self, models_list, brequires):\n",
    "        for i in range(len(models_list)):\n",
    "            for p in models_list[i].parameters():\n",
    "                p.requires_grad = brequires\n",
    "\n",
    "    def save_img_results(self, netG, noise, sent_emb, words_embs, mask,\n",
    "                         image_encoder, captions, cap_lens,\n",
    "                         gen_iterations, name='current'):\n",
    "        # Save images\n",
    "        fake_imgs, attention_maps, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
    "        for i in range(len(attention_maps)):\n",
    "            if len(fake_imgs) > 1:\n",
    "                img = fake_imgs[i + 1].detach().cpu()\n",
    "                lr_img = fake_imgs[i].detach().cpu()\n",
    "            else:\n",
    "                img = fake_imgs[0].detach().cpu()\n",
    "                lr_img = None\n",
    "            attn_maps = attention_maps[i]\n",
    "            att_sze = attn_maps.size(2)\n",
    "            img_set, _ = \\\n",
    "                build_super_images(img, captions, self.ixtoword,\n",
    "                                   attn_maps, att_sze, lr_imgs=lr_img)\n",
    "            if img_set is not None:\n",
    "                im = Image.fromarray(img_set)\n",
    "                fullpath = '%s/G_%s_%d_%d.png'\\\n",
    "                    % (self.image_dir, name, gen_iterations, i)\n",
    "                im.save(fullpath)\n",
    "\n",
    "        # for i in range(len(netsD)):\n",
    "        i = -1\n",
    "        img = fake_imgs[i].detach()\n",
    "        region_features, _ = image_encoder(img)\n",
    "        att_sze = region_features.size(2)\n",
    "        _, _, att_maps = words_loss(region_features.detach(),\n",
    "                                    words_embs.detach(),\n",
    "                                    None, cap_lens,\n",
    "                                    None, self.batch_size)\n",
    "        img_set, _ = \\\n",
    "            build_super_images(fake_imgs[i].detach().cpu(),\n",
    "                               captions, self.ixtoword, att_maps, att_sze)\n",
    "        if img_set is not None:\n",
    "            im = Image.fromarray(img_set)\n",
    "            fullpath = '%s/D_%s_%d.png'\\\n",
    "                % (self.image_dir, name, gen_iterations)\n",
    "            im.save(fullpath)\n",
    "\n",
    "    def train(self):\n",
    "        text_encoder, image_encoder, netG, netsD, start_epoch = self.build_models()\n",
    "        avg_param_G = copy_G_params(netG)\n",
    "        optimizerG, optimizersD = self.define_optimizers(netG, netsD)\n",
    "        real_labels, fake_labels, match_labels = self.prepare_labels()\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "        nz = cfg.GAN.Z_DIM\n",
    "        noise = Variable(torch.FloatTensor(batch_size, nz))\n",
    "        fixed_noise = Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1))\n",
    "        if cfg.CUDA:\n",
    "            noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "        gen_iterations = 0\n",
    "        # gen_iterations = start_epoch * self.num_batches\n",
    "        for epoch in range(start_epoch, self.max_epoch):\n",
    "            start_t = time.time()\n",
    "\n",
    "            data_iter = iter(self.data_loader)\n",
    "            step = 0\n",
    "            while step < self.num_batches:\n",
    "                # num_batches  batch size\n",
    "                # reset requires_grad to be trainable for all Ds\n",
    "                # self.set_requires_grad_value(netsD, True)\n",
    "\n",
    "                ######################################################\n",
    "                # (1) Prepare training data and Compute text embeddings\n",
    "                ######################################################\n",
    "                data = data_iter.next()\n",
    "                imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
    "\n",
    "                hidden = text_encoder.init_hidden(batch_size)\n",
    "                # words_embs: batch_size x nef x seq_len\n",
    "                # sent_emb: batch_size x nef\n",
    "                words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
    "                words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
    "                mask = (captions == 0)\n",
    "                num_words = words_embs.size(2)\n",
    "                if mask.size(1) > num_words:\n",
    "                    mask = mask[:, :num_words]\n",
    "\n",
    "                #######################################################\n",
    "                # (2) Generate fake images\n",
    "                ######################################################\n",
    "                noise.data.normal_(0, 1)\n",
    "                fake_imgs, _, mu, logvar = netG(noise, sent_emb, words_embs, mask)\n",
    "\n",
    "                #######################################################\n",
    "                # (3) Update D network\n",
    "                ######################################################\n",
    "                errD_total = 0\n",
    "                D_logs = ''\n",
    "                for i in range(len(netsD)):\n",
    "                    netsD[i].zero_grad()\n",
    "                    errD = discriminator_loss(netsD[i], imgs[i], fake_imgs[i],\n",
    "                                              sent_emb, real_labels, fake_labels)\n",
    "                    # backward and update parameters\n",
    "                    errD.backward()\n",
    "                    optimizersD[i].step()\n",
    "                    errD_total += errD\n",
    "                    D_logs += 'errD%d: %.2f ' % (i, errD.data[0])\n",
    "\n",
    "                #######################################################\n",
    "                # (4) Update G network: maximize log(D(G(z)))\n",
    "                ######################################################\n",
    "                # compute total loss for training G\n",
    "                step += 1\n",
    "                gen_iterations += 1\n",
    "\n",
    "                # do not need to compute gradient for Ds\n",
    "                # self.set_requires_grad_value(netsD, False)\n",
    "                netG.zero_grad()\n",
    "                errG_total, G_logs = \\\n",
    "                    generator_loss(netsD, image_encoder, fake_imgs, real_labels,\n",
    "                                   words_embs, sent_emb, match_labels, cap_lens, class_ids)\n",
    "                kl_loss = KL_loss(mu, logvar)\n",
    "                errG_total += kl_loss\n",
    "                G_logs += 'kl_loss: %.2f ' % kl_loss.data[0]\n",
    "                # backward and update parameters\n",
    "                errG_total.backward()\n",
    "                optimizerG.step()\n",
    "                ############ why???? \n",
    "                for p, avg_p in zip(netG.parameters(), avg_param_G):\n",
    "                    avg_p.mul_(0.999).add_(0.001, p.data)\n",
    "\n",
    "                if gen_iterations % 100 == 0:\n",
    "                    print(D_logs + '\\n' + G_logs)\n",
    "                # save images\n",
    "                if gen_iterations % 1000 == 0:\n",
    "                    backup_para = copy_G_params(netG)\n",
    "                    load_params(netG, avg_param_G)\n",
    "                    self.save_img_results(netG, fixed_noise, sent_emb,\n",
    "                                          words_embs, mask, image_encoder,\n",
    "                                          captions, cap_lens, epoch, name='average')\n",
    "                    load_params(netG, backup_para)\n",
    "                    #\n",
    "                    # self.save_img_results(netG, fixed_noise, sent_emb,\n",
    "                    #                       words_embs, mask, image_encoder,\n",
    "                    #                       captions, cap_lens,\n",
    "                    #                       epoch, name='current')\n",
    "            end_t = time.time()\n",
    "\n",
    "            print('''[%d/%d][%d]\n",
    "                  Loss_D: %.2f Loss_G: %.2f Time: %.2fs'''\n",
    "                  % (epoch, self.max_epoch, self.num_batches,\n",
    "                     errD_total.data[0], errG_total.data[0],\n",
    "                     end_t - start_t))\n",
    "\n",
    "            if epoch % cfg.TRAIN.SNAPSHOT_INTERVAL == 0:  # and epoch != 0:\n",
    "                self.save_model(netG, avg_param_G, netsD, epoch)\n",
    "\n",
    "        self.save_model(netG, avg_param_G, netsD, self.max_epoch)\n",
    "\n",
    "    def save_singleimages(self, images, filenames, save_dir,\n",
    "                          split_dir, sentenceID=0):\n",
    "        for i in range(images.size(0)):\n",
    "            s_tmp = '%s/single_samples/%s/%s' %\\\n",
    "                (save_dir, split_dir, filenames[i])\n",
    "            folder = s_tmp[:s_tmp.rfind('/')]\n",
    "            if not os.path.isdir(folder):\n",
    "                print('Make a new folder: ', folder)\n",
    "                mkdir_p(folder)\n",
    "\n",
    "            fullpath = '%s_%d.jpg' % (s_tmp, sentenceID)\n",
    "            # range from [-1, 1] to [0, 1]\n",
    "            # img = (images[i] + 1.0) / 2\n",
    "            img = images[i].add(1).div(2).mul(255).clamp(0, 255).byte()\n",
    "            # range from [0, 1] to [0, 255]\n",
    "            ndarr = img.permute(1, 2, 0).data.cpu().numpy()\n",
    "            im = Image.fromarray(ndarr)\n",
    "            im.save(fullpath)\n",
    "\n",
    "    def sampling(self, split_dir):\n",
    "        if cfg.TRAIN.NET_G == '':\n",
    "            print('Error: the path for morels is not found!')\n",
    "        else:\n",
    "            if split_dir == 'test':\n",
    "                split_dir = 'valid'\n",
    "            # Build and load the generator\n",
    "            if cfg.GAN.B_DCGAN:\n",
    "                netG = G_DCGAN()\n",
    "            else:\n",
    "                netG = G_NET()\n",
    "            netG.apply(weights_init)\n",
    "            netG.cuda()\n",
    "            netG.eval()\n",
    "            #\n",
    "            text_encoder = RNN_ENCODER(self.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
    "            state_dict = \\\n",
    "                torch.load(cfg.TRAIN.NET_E, map_location=lambda storage, loc: storage)\n",
    "            text_encoder.load_state_dict(state_dict)\n",
    "            print('Load text encoder from:', cfg.TRAIN.NET_E)\n",
    "            text_encoder = text_encoder.cuda()\n",
    "            text_encoder.eval()\n",
    "\n",
    "            batch_size = self.batch_size\n",
    "            nz = cfg.GAN.Z_DIM\n",
    "            noise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n",
    "            noise = noise.cuda()\n",
    "\n",
    "            model_dir = cfg.TRAIN.NET_G\n",
    "            state_dict = \\\n",
    "                torch.load(model_dir, map_location=lambda storage, loc: storage)\n",
    "            # state_dict = torch.load(cfg.TRAIN.NET_G)\n",
    "            netG.load_state_dict(state_dict)\n",
    "            print('Load G from: ', model_dir)\n",
    "\n",
    "            # the path to save generated images\n",
    "            s_tmp = model_dir[:model_dir.rfind('.pth')]\n",
    "            save_dir = '%s/%s' % (s_tmp, split_dir)\n",
    "            mkdir_p(save_dir)\n",
    "\n",
    "            cnt = 0\n",
    "\n",
    "            for _ in range(1):  # (cfg.TEXT.CAPTIONS_PER_IMAGE):\n",
    "                for step, data in enumerate(self.data_loader, 0):\n",
    "                    cnt += batch_size\n",
    "                    if step % 100 == 0:\n",
    "                        print('step: ', step)\n",
    "                    # if step > 50:\n",
    "                    #     break\n",
    "\n",
    "                    imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
    "\n",
    "                    hidden = text_encoder.init_hidden(batch_size)\n",
    "                    # words_embs: batch_size x nef x seq_len\n",
    "                    # sent_emb: batch_size x nef\n",
    "                    words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
    "                    words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
    "                    mask = (captions == 0)\n",
    "                    num_words = words_embs.size(2)\n",
    "                    if mask.size(1) > num_words:\n",
    "                        mask = mask[:, :num_words]\n",
    "\n",
    "                    #######################################################\n",
    "                    # (2) Generate fake images\n",
    "                    ######################################################\n",
    "                    noise.data.normal_(0, 1)\n",
    "                    fake_imgs, _, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
    "                    for j in range(batch_size):\n",
    "                        s_tmp = '%s/single/%s' % (save_dir, keys[j])\n",
    "                        folder = s_tmp[:s_tmp.rfind('/')]\n",
    "                        if not os.path.isdir(folder):\n",
    "                            print('Make a new folder: ', folder)\n",
    "                            mkdir_p(folder)\n",
    "                        k = -1\n",
    "                        # for k in range(len(fake_imgs)):\n",
    "                        im = fake_imgs[k][j].data.cpu().numpy()\n",
    "                        # [-1, 1] --> [0, 255]\n",
    "                        im = (im + 1.0) * 127.5\n",
    "                        im = im.astype(np.uint8)\n",
    "                        im = np.transpose(im, (1, 2, 0))\n",
    "                        im = Image.fromarray(im)\n",
    "                        fullpath = '%s_s%d.png' % (s_tmp, k)\n",
    "                        im.save(fullpath)\n",
    "\n",
    "    def gen_example(self, data_dic):\n",
    "        if cfg.TRAIN.NET_G == '':\n",
    "            print('Error: the path for morels is not found!')\n",
    "        else:\n",
    "            # Build and load the generator\n",
    "            text_encoder = \\\n",
    "                RNN_ENCODER(self.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
    "            state_dict = \\\n",
    "                torch.load(cfg.TRAIN.NET_E, map_location=lambda storage, loc: storage)\n",
    "            text_encoder.load_state_dict(state_dict)\n",
    "            print('Load text encoder from:', cfg.TRAIN.NET_E)\n",
    "            text_encoder = text_encoder.cuda()\n",
    "            text_encoder.eval()\n",
    "\n",
    "            # the path to save generated images\n",
    "            if cfg.GAN.B_DCGAN:\n",
    "                netG = G_DCGAN()\n",
    "            else:\n",
    "                netG = G_NET()\n",
    "            s_tmp = cfg.TRAIN.NET_G[:cfg.TRAIN.NET_G.rfind('.pth')]\n",
    "            model_dir = cfg.TRAIN.NET_G\n",
    "            state_dict = \\\n",
    "                torch.load(model_dir, map_location=lambda storage, loc: storage)\n",
    "            netG.load_state_dict(state_dict)\n",
    "            print('Load G from: ', model_dir)\n",
    "            netG.cuda()\n",
    "            netG.eval()\n",
    "            for key in data_dic:\n",
    "                save_dir = '%s/%s' % (s_tmp, key)\n",
    "                mkdir_p(save_dir)\n",
    "                captions, cap_lens, sorted_indices = data_dic[key]\n",
    "\n",
    "                batch_size = captions.shape[0]\n",
    "                nz = cfg.GAN.Z_DIM\n",
    "                captions = Variable(torch.from_numpy(captions), volatile=True)\n",
    "                cap_lens = Variable(torch.from_numpy(cap_lens), volatile=True)\n",
    "\n",
    "                captions = captions.cuda()\n",
    "                cap_lens = cap_lens.cuda()\n",
    "                for i in range(1):  # 16\n",
    "                    noise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n",
    "                    noise = noise.cuda()\n",
    "                    #######################################################\n",
    "                    # (1) Extract text embeddings\n",
    "                    ######################################################\n",
    "                    hidden = text_encoder.init_hidden(batch_size)\n",
    "                    # words_embs: batch_size x nef x seq_len\n",
    "                    # sent_emb: batch_size x nef\n",
    "                    words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
    "                    mask = (captions == 0)\n",
    "                    #######################################################\n",
    "                    # (2) Generate fake images\n",
    "                    ######################################################\n",
    "                    noise.data.normal_(0, 1)\n",
    "                    fake_imgs, attention_maps, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
    "                    # G attention\n",
    "                    cap_lens_np = cap_lens.cpu().data.numpy()\n",
    "                    for j in range(batch_size):\n",
    "                        save_name = '%s/%d_s_%d' % (save_dir, i, sorted_indices[j])\n",
    "                        for k in range(len(fake_imgs)):\n",
    "                            im = fake_imgs[k][j].data.cpu().numpy()\n",
    "                            im = (im + 1.0) * 127.5\n",
    "                            im = im.astype(np.uint8)\n",
    "                            # print('im', im.shape)\n",
    "                            im = np.transpose(im, (1, 2, 0))\n",
    "                            # print('im', im.shape)\n",
    "                            im = Image.fromarray(im)\n",
    "                            fullpath = '%s_g%d.png' % (save_name, k)\n",
    "                            im.save(fullpath)\n",
    "\n",
    "                        for k in range(len(attention_maps)):\n",
    "                            if len(fake_imgs) > 1:\n",
    "                                im = fake_imgs[k + 1].detach().cpu()\n",
    "                            else:\n",
    "                                im = fake_imgs[0].detach().cpu()\n",
    "                            attn_maps = attention_maps[k]\n",
    "                            att_sze = attn_maps.size(2)\n",
    "                            img_set, sentences = \\\n",
    "                                build_super_images2(im[j].unsqueeze(0),\n",
    "                                                    captions[j].unsqueeze(0),\n",
    "                                                    [cap_lens_np[j]], self.ixtoword,\n",
    "                                                    [attn_maps[j]], att_sze)\n",
    "                            if img_set is not None:\n",
    "                                im = Image.fromarray(img_set)\n",
    "                                fullpath = '%s_a%d.png' % (save_name, k)\n",
    "                                im.save(fullpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
